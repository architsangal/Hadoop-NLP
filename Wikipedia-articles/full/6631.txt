{ PCI Express bus card slots (from top to bottom: x4, x16, x1 and x16), compared to a 32-bit } { conventional PCI bus card slot (very bottom) } In computer architecture, a bus is a subsystem that transfers data between components inside a computer, or between computers. Early computer buses were literally parallel electrical wires with multiple connections, but the term is now used for any physical arrangement that provides the same logical functionality as a parallel electrical bus. Modern computer buses can use both parallel and bit serial connections, and can be wired in either a multidrop (electrical parallel) or daisy chain topology, or connected by switched hubs, as in the case of USB. [ Background and nomenclature ] Computer systems generally consist of three main parts, the central processing unit (CPU) to process data, main memory to hold the data to be processed, and a variety of peripherals to communicate that data with the outside world. An early computer might use a hand-wired CPU of vacuum tube s, a magnetic drum for main memory, and a punch tape and printer for reading and writing data. In a modern system we might find an AMD Opteron CPU, DDR3 SDRAM for memory, a hard drive for offline data, a graphics card and LCD display as a display system, a mouse and keyboard for interaction, and a Wi-Fi connection for networking. In both examples, computer buses of one form or another move data between all of these devices. In most traditional computer architecture s, the CPU and main memory tend to be tightly coupled. The microprocessor conventionally has a number of electrical connections called &quot; pins &quot; that can be used to select an &quot; address &quot; in the main memory, and another set of pins to read and write the data stored at that location. In most cases, the CPU and memory share signalling characteristics and operate in synchrony. The bus connecting the CPU and memory is one of the defining characteristics of the system, and often referred to simply as the system bus. It is possible to allow peripherals to communicate with memory in the same fashion, attaching adaptors in the form of expansion card s directly to the system bus. This is commonly accomplished through some sort of standardized electrical connector, several of these forming the expansion bus or local bus. However, as the performance differences between the CPU and peripherals varies widely, some solution is generally needed to ensure that peripherals do not slow overall system performance. Many CPUs feature a second set of pins similar to those for communicating with memory, but able to operate at very different speeds and using different protocols. Others use smart controllers to place the data directly in memory, a concept known as direct memory access. Most modern systems combine both solutions, where appropriate. As the number of potential peripherals grew, using an expansion card for every peripheral became increasingly untenable. This has led to the introduction of bus systems designed specifically to support multiple peripherals. Common examples are the SATA ports in modern computers, which allow a number of hard drives to be connected without the need for a card. However, these high-performance systems are generally too expensive to implement in low-end devices, like a mouse. This has led to the parallel development of a number of low-performance bus systems for these solutions, the most common example being Universal Serial Bus. All such examples may be referred to as peripheral bus es, although this terminology is not universal. In modern systems the performance difference between the CPU and main memory has grown so great that increasing amounts of high-speed memory is built directly into the CPU, known as a cache. In such systems, CPUs communicate using high-performance buses that operate at speeds much greater than memory, and communicate with memory using protocols similar to those used solely for peripherals in the past. These system buses are also used to communicate with most (or all) other peripherals, through adaptors, which in turn talk to other peripherals and controllers. Such systems are architecturally more similar to multicomputers, communicating over a bus rather than a network. In these cases, expansion buses are entirely separate and no longer share any architecture with their host CPU (and may in fact support many different CPUs, as is the case with PCI ). What would have formerly been a system bus is now often known as a front-side bus. Given these changes, the classical terms &quot; system &quot;, &quot; expansion &quot; and &quot; peripheral &quot; no longer have the same connotations. Other common categorization systems are based on the buses primary role, connecting devices internally or externally, PCI vs. SCSI for instance. However, many common modern bus systems can be used for both; SATA and the associated eSATA are one example of a system that would formerly be described as internal, while in certain automotive applications use the primarily external IEEE 1394 in a fashion more similar to a system bus. Other examples, like InfiniBand and I²C were designed from the start to be used both internally and externally. To further confuse issues, it was common in the past to classify bus systems based on the communications system they used, serial or parallel. Many modern systems can operate in either mode, depending on the application. [ Implementation details ] At one time, &quot; bus &quot; meant an electrically parallel system, with electrical conductors similar or identical to the pins on the CPU. This is no longer the case, and modern systems are blurring the lines between buses and networks. Buses can be parallel buses, which carry data words in parallel on multiple wires, or serial bus es, which carry data in bit-serial form. The addition of extra power and control connections, differential drivers, and data connections in each direction usually means that most serial buses have more conductors than the minimum of one used in 1-Wire and UNI/O. As data rates increase, the problems of timing skew, power consumption, electromagnetic interference and crosstalk across parallel buses become more and more difficult to circumvent. One partial solution to this problem has been to double pump the bus. Often, a serial bus can be operated at higher overall data rates than a parallel bus, despite having fewer electrical connections, because a serial bus inherently has no timing skew or crosstalk. USB, FireWire, and Serial ATA are examples of this. Multidrop connections do not work well for fast serial buses, so most modern serial buses use daisy-chain or hub designs. Network connections such as Ethernet are not generally regarded as buses, although the difference is largely conceptual rather than practical. An attribute generally used to characterize a bus is that power is provided by the bus for the connected hardware. This conceptualization emphasizes the busbar origins of bus architecture as supplying switched or distributed power. Conventionally, this consideration was used to exclude, as buses, hardware connection schemes such as the serial RS-232 and parallel Centronics and IEEE 1284 interfaces (and Ethernet above) where the typical devices, such as modems and printers, needed to be plugged into power outlets. However, Universal Serial Bus devices may or may not use the bus supplied power, often using the devices&apos; internal batteries instead. This distinction is exemplified by a telephone system with a connected modem, where the RJ11 connection and associated modulated signaling scheme is not considered a bus, and is analogous to an Ethernet connection. It should be noted that a phone line connection scheme is not considered to be a bus even though the phone is powered by the POTS system but yet, in the Central Office, buses are used with cross-bar switch es for connections between phones. [ History ] [ First generation ] Early computer buses were bundles of wire that attached computer memory and peripherals. Anecdotally termed the &quot; digit trunk &quot;, { See the early Australian } { CSIRAC computer } they were named after electrical power buses, or busbar s. Almost always, there was one bus for memory, and one or more separate buses for peripherals. These were accessed by separate instructions, with completely different timings and protocols. One of the first complications was the use of interrupt s. Early computer programs performed I/O by waiting in a loop for the peripheral to become ready. This was a waste of time for programs that had other tasks to do. Also, if the program attempted to perform those other tasks, it might take too long for the program to check again, resulting in loss of data. Engineers thus arranged for the peripherals to interrupt the CPU. The interrupts had to be prioritized, because the CPU can only execute code for one peripheral at a time, and some devices are more time-critical than others. High-end systems introduced the idea of channel controller s, which were essentially small computers dedicated to handing the input and output of a given bus. IBM introduced these on the IBM 709 in 1958, and they became a common feature of their platforms. Other high-performance vendors like Control Data Corporation implemented similar designs. In generally, the channel controllers would do their best to run all of the bus operations internally, moving data when the CPU was known to be busy elsewhere if possible, and only using interrupts when necessary. This greatly reduced CPU load, and provided better overall system performance. { system bus } To provide modularity, memory and I/O buses can be combined into a unified system bus. [ The essentials of computer organization and architecture Linda Null Julia Lobur Jones &amp; Bartlett Learning 2006 978-0-7637-3769-6 2nd 33,179–181 http://books.google.com/books?id%3DQGPHAl9GE-IC%26amp%3Bpg%3DPA33 ] In this case, a single mechanical and electrical system can be used to connect together many of the system components, or in some cases, all of them. Later computer programs began to share memory common to several CPUs. Access to this memory bus had to be prioritized, as well. The simple way to prioritize interrupts or bus access was with a daisy chain. In this case signals will naturally flow through the bus in physical or logical order, eliminating the need for complex scheduling. [ Minis and micros ] Digital Equipment Corporation (DEC) further reduced cost for mass-produced minicomputer s, and mapped peripherals into the memory bus, so that the input and output devices appeared to be memory locations. This was implemented in the Unibus of the PDP-11 around 1969. [ A New Architecture for Mini-Computers—The DEC PDP-11 C. Gordon Bell R. Cady H. McFarland B. Delagi J. O&apos;Laughlin R. Noonan W. Wulf Spring Joint Computer Conference 657–675 1970 http://research.microsoft.com/en-us/um/people/gbell/CGB%20Files/New%20Architecture%20PDP11%20SJCC%201970%20c.pdf ] Early microcomputer bus systems were essentially a passive backplane connected directly or through buffer amplifiers to the pins of the CPU. Memory and other devices would be added to the bus using the same address and data pins as the CPU itself used, connected in parallel. Communication was controlled by the CPU, which had read and written data from the devices as if they are blocks of memory, using the same instructions, all timed by a central clock controlling the speed of the CPU. Still, devices interrupt ed the CPU by signaling on separate CPU pins. { For instance, a } { disk drive controller would signal the CPU that new data was ready to be read, at which point the CPU would move the data by reading the &quot; memory location &quot; that corresponded to the disk drive. Almost all early microcomputers were built in this fashion, starting with the } { S-100 bus in the } { Altair 8800 computer system. } In some instances, most notably in the IBM PC, although similar physical architecture can be employed, instructions to access peripherals ( in and out ) and memory ( mov and others) have not been made uniform at all, and still generate distinct CPU signals, that could be used to implement a separate I/O bus. These simple bus systems had a serious drawback when used for general-purpose computers. All the equipment on the bus has to talk at the same speed, as it shared a single clock. Increasing the speed of the CPU becomes harder, because the speed of all the devices must increase as well. When it is not practical or economical to have all devices as fast as the CPU, the CPU must either enter a wait state, or work at a slower clock frequency temporarily, [ Bray Andrew C. Dickens, Adrian C.; Holmes, Mark A. The Advanced User Guide for the BBC Microcomputer http://www.nvg.org/bbc/doc/BBCAdvancedUserGuide-PDF.zip zipped PDF 2008-03-28 1983 Cambridge Microcomputer Centre Cambridge, UK 0-946827-00-1 442–443 28. The One Megahertz bus ] to talk to other devices in the computer. While acceptable in embedded systems, this problem was not tolerated for long in general-purpose, user-expandable computers. Such bus systems are also difficult to configure when constructed from common off-the-shelf equipment. Typically each added expansion card requires many jumpers in order to set memory addresses, I/O addresses, interrupt priorities, and interrupt numbers. [ Second generation ] &quot; Second generation &quot; bus systems like NuBus addressed some of these problems. They typically separated the computer into two &quot; worlds &quot;, the CPU and memory on one side, and the various devices on the other. A bus controller accepted data from the CPU side to be moved to the peripherals side, thus shifting the communications protocol burden from the CPU itself. This allowed the CPU and memory side to evolve separately from the device bus, or just &quot; bus &quot;. Devices on the bus could talk to each other with no CPU intervention. This led to much better &quot; real world &quot; performance, but also required the cards to be much more complex. These buses also often addressed speed issues by being &quot; bigger &quot; in terms of the size of the data path, moving from 8-bit parallel bus es in the first generation, to 16 or 32-bit in the second, as well as adding software setup (now standardised as Plug-n-play ) to supplant or replace the jumpers. However these newer systems shared one quality with their earlier cousins, in that everyone on the bus had to talk at the same speed. While the CPU was now isolated and could increase speed without fear, CPUs and memory continued to increase in speed much faster than the buses they talked to. The result was that the bus speeds were now very much slower than what a modern system needed, and the machines were left starved for data. A particularly common example of this problem was that video card s quickly outran even the newer bus systems like PCI, and computers began to include AGP just to drive the video card. By 2004 AGP was outgrown again by high-end video cards and other peripherals and has been replaced by the new PCI Express bus. An increasing number of external devices started employing their own bus systems as well. When disk drives were first introduced, they would be added to the machine with a card plugged into the bus, which is why computers have so many slots on the bus. But through the 1980s and 1990s, new systems like SCSI and IDE were introduced to serve this need, leaving most slots in modern systems empty. Today there are likely to be about five different buses in the typical machine, supporting various devices. [ Third generation ] &quot; Third generation &quot; buses have been emerging into the market since about 2001, including HyperTransport and InfiniBand. They also tend to be very flexible in terms of their physical connections, allowing them to be used both as internal buses, as well as connecting different machines together. This can lead to complex problems when trying to service different requests, so much of the work on these systems concerns software design, as opposed to the hardware itself. In general, these third generation buses tend to look more like a network than the original concept of a bus, with a higher protocol overhead needed than early systems, while also allowing multiple devices to use the bus at once. Buses such as Wishbone have been developed by the open source hardware movement in an attempt to further remove legal and patent constraints from computer design. [ Bus network ] [ Examples of internal computer buses ] [ Parallel ] ASUS Media Bus proprietary, used on some ASUS Socket 7 motherboards Computer Automated Measurement and Control (CAMAC) for instrumentation systems Extended ISA or EISA Industry Standard Architecture or ISA Low Pin Count or LPC MBus MicroChannel or MCA Multibus for industrial systems NuBus or IEEE 1196 OPTi local bus used on early Intel 80486 motherboards. Conventional PCI Parallel ATA (aka Advanced Technology Attachment, ATA, PATA, IDE, EIDE, ATAPI, etc.) disk/tape peripheral attachment bus S-100 bus or IEEE 696, used in the Altair and similar microcomputers SBus or IEEE 1496 SS-50 Bus Runway bus, a proprietary front side CPU bus developed by Hewlett-Packard for use by its PA-RISC microprocessor family GSC/HSC, a proprietary peripheral bus developed by Hewlett-Packard for use by its PA-RISC microprocessor family Precision Bus, a proprietary bus developed by Hewlett-Packard for use by its HP3000 computer family STEbus STD Bus (for STD-80 [8-bit] and STD32 [16-/32-bit] ), FAQ Unibus, a proprietary bus developed by Digital Equipment Corporation for their PDP-11 and early VAX computers. Q-Bus, a proprietary bus developed by Digital Equipment Corporation for their PDP and later VAX computers. VESA Local Bus or VLB or VL-bus VMEbus, the VERSAmodule Eurocard bus PC/104 PC/104 Plus PC/104 Express PCI-104 PCIe-104 Zorro II and Zorro III, used in Amiga computer systems [ Serial ] 1-Wire HyperTransport I²C PCI Express or PCIe Serial ATA (SATA) Serial Peripheral Interface Bus or SPI bus UNI/O SMBus [ Examples of external computer buses ] [ Parallel ] HIPPI HIgh Performance Parallel Interface IEEE-488 (aka GPIB, General-Purpose Interface Bus, and HPIB, Hewlett-Packard Instrumentation Bus) PC Card, previously known as PCMCIA, much used in laptop computers and other portables, but fading with the introduction of USB and built-in network and modem connections [ Serial ] USB Universal Serial Bus, used for a variety of external devices Controller area network ( &quot; CAN bus &quot; ) EIA-485 eSATA IEEE 1394 interface (FireWire) ExpressCard [ Examples of internal/external computer buses ] Futurebus InfiniBand QuickRing Scalable Coherent Interface (SCI) SCSI Small Computer System Interface, disk/tape peripheral attachment bus Serial Attached SCSI (SAS) and other serial SCSI buses Yapbus, a proprietary bus developed for the Pixar Image Computer [ See also ] Address bus Bus contention Control bus Expansion bus Front-side bus (FSB) External Bus Interface (EBI) Harvard architecture Network On Chip List of device bandwidths [ References ] [ External links ] [ Computers/Hardware/Buses/ Computer hardware buses ] Chip Weems&apos; Lecture 12: Buses Computer hardware buses and slots pinouts with brief descriptions Category:Digital electronics Category:Motherboard af:Rekenaarbus az:Şin (kompyuter) bn:বাস (কম্পিউটার) bs:Sabirnica br:Bus stlennegel ca:Bus (informàtica) cs:Sběrnice da:Bus (datakommunikation) de:Bus (Datenverarbeitung) et:Siin es:Bus (informática) eo:Buso (komputiko) fr:Bus informatique ko:버스 (컴퓨팅) hr:Sabirnica id:Bus komputer it:Bus (informatica) he:אפיק נתונים kk:Құрсым lv:Kopne lb:Bus (Sammelleitung) lt:Magistralė (kompiuteris) hu:Busz (informatika) mn:Мэдээлэл дамжуулах түгээгүүр my:ဘတ်စ် (ကွန်ပျူတာ) ja:バス (コンピュータ) nn:Bussystem mhr:Системшай pl:Szyna danych pt:Barramento ru:Шина (компьютер) si:සූදානම් ක්‍රමවේදය (Bus Topology) simple:Computer bus sl:Vodilo sr:Магистрала (рачунарство) fi:Väylä sv:Buss (elektronisk term) tl:Bus ng kompyuter ta:தரவுப் பாட்டை th:BUS tr:Bilgisayar veri yolu uk:Комп&apos;ютерна шина vi:Bus (máy tính) zh:总线