In computer operating system s, read-copy-update (RCU) is a synchronization mechanism implementing a kind of mutual exclusion { RCU does not implement mutual exclusion in the conventional sense: RCU readers can and do run concurrently with RCU updates. RCU&apos;s variant of mutual exclusion is in space, with RCU readers accessing old versions of data being concurrently updated, rather than in time, as is the case for conventional concurrency-control mechanisms. } which can sometimes be used as an alternative to a readers-writer lock. It allows extremely low overhead, wait-free reads. However, RCU updates can be expensive, as they must leave the old versions of the data structure in place to accommodate pre-existing readers. These old versions are reclaimed after all pre-existing readers finish their accesses. [ Overview ] RCU features read-side critical sections, which are normally delimited by rcu_read_lock() and rcu_read_unlock(). Any statement that is not within an RCU read-side critical section is said to be a quiescent state, and such statements are not permitted to hold references to RCU-protected data structures. Any time period during which each thread resides at least one quiescent state is called a grace period. By definition, any RCU read-side critical section in existence at the beginning of a given grace period must complete before the end of that grace period, which constitutes the fundamental guarantee provided by RCU. It turns out that this guarantee can be provided with extremely small read-side overheads, in fact, in the limiting case that is actually realized by server-class Linux-kernel builds, the read-side overhead is exactly zero. [ Guniguntala Dinakar McKenney Paul E. Triplett Joshua Walpole Jonathan The read-copy-update mechanism for supporting real-time applications on shared-memory multiprocessor systems with Linux IBM Systems Journal 47 221–236 April-June 2008 10.1147/sj.472.0221 2 ] RCU&apos;s fundamental guarantee may be used by splitting updates into removal and reclamation phases. The removal phase removes references to data items within a data structure (possibly by replacing them with references to new versions of these data items), and can run concurrently with RCU read-side critical sections. The reason that it is safe to run the removal phase concurrently with RCU readers is the semantics of modern CPUs guarantee that readers will see either the old or the new version of the data structure rather than a partially updated reference. Once a grace period has elapsed, there can no longer be any readers referencing the old version, so it is then safe for the reclamation phase to free (reclaim) the data items that made up that old version. [ McKenney Paul E. Walpole Jonathan What is RCU, Fundamentally? Linux Weekly News December 17, 2007 http://lwn.net/Articles/262464/ September 24, 2010 ] Splitting an update into removal and reclamation phases allows the updater to perform the removal phase immediately, and to defer the reclamation phase until all readers active during the removal phase have completed, in other words, until a grace period has elapsed. { Only readers that are active during the removal phase need be considered, because any reader starting after the removal phase will be unable to gain a reference to the removed data items, and therefore cannot be disrupted by the reclamation phase. } So the typical RCU update sequence goes something like the following: [ McKenney Paul E. Slingwine John D. Read-Copy Update: Using Execution History to Solve Concurrency Problems http://www.rdrop.com/users/paulmck/RCU/rclockpdcsproof.pdf Parallel and Distributed Computing and Systems 509–518 October 1998 1998 ] Ensure that all readers accessing RCU-protected data structures carry out their references from within an RCU read-side critical section. Remove pointers to a data structure, so that subsequent readers cannot gain a reference to it. Wait for a grace period to elapse, so that all previous readers (which might still have pointers to the data structure removed in the prior step) will have completed their RCU read-side critical sections. At this point, there cannot be any readers still holding references to the data structure, so it now may safely be reclaimed (e.g., freed). Garbage collectors, where available, may be used to perform this step. In the above procedure, the updater is performing both the removal and the reclamation step, but it is often helpful for an entirely different thread to do the reclamation. Reference counting can be used to let the reader perform removal so, even if the same thread performs both the update step (step (2) above) and the reclamation step (step (4) above), it is often helpful to think of them separately. [ Uses ] As of early 2008, there were almost 2,000 uses of the RCU API within the Linux kernel [ McKenney Paul E. Walpole Jonathan Introducing technology into the Linux kernel: a case study http://portal.acm.org/citation.cfm?doid%3D1400097.1400099 SIGOPS Oper. Syst. Rev. 42 4–17 July 2008 10.1145/1400097.1400099 5 ] including the networking protocol stacks [ Olsson Robert Nilsson Stefan TRASH: A dynamic LC-trie and hash table structure http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber%3D4281239 Workshop on High Performance Switching and Routing (HPSR&apos;07) May, 2007 2007 ] and the memory-management system [ Piggin Nick A Lockless Pagecache in Linux---Introduction, Progress, Performance http://www.linuxsymposium.org/2006/view_abstract.php?content_key%3D184 Ottawa Linux Symposium July, 2006 2006 ].As of 2011, there were more than 5,000 uses { http://www.rdrop.com/users/paulmck/RCU/linuxusage.html }.Since 2006, researchers have applied RCU and similar techniques to a number of problems, including management of metadata used in dynamic analysis, [ Kannan Hari Ordering decoupled metadata accesses in multiprocessors 10.1145/1669112.1669161 978-1-60558-798-1 MICRO 42: Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture 381–390 New York, NY, USA 2009 ] managing the lifetime of clustered objects, [ Matthews Chris Coady Yvonne Appavoo Jonathan Portability events: a programming model for scalable system infrastructures 10.1145/1215995.1216006 1-59593-577-0 PLOS &apos;06: Proceedings of the 3rd workshop on Programming languages and operating systems San Jose, CA, USA 2009 ] managing object lifetime in the K42 research operating system, [ Da Silva Dilma Krieger Orran Wisniewski Robert W. Waterland Amos Tam David Baumann Andrew K42: an infrastructure for operating system research 10.1145/1131322.1131333 SIGOPS Oper. Syst. Rev. 40 34–42 April 2006 2 ] [ Appavoo Jonathan Da Silva Dilma Krieger Orran Auslander Mark Ostrowski Michal Rosenburg Bryan Waterland Amos Wisniewski Robert W. Xenidis Jimi Experience distributing objects in an SMMP OS 10.1145/1275517.1275518 ACM Trans. Comput. Syst. 25 6/1–6/52 August 2007 3 ] and optimizing software transactional memory implementations. [ Fraser Keir Harris Tim Concurrent programming without locks 10.1145/1233307.1233309 ACM Trans. Comput. Syst. ACM New York, NY, USA 25 34–42 2007 2 ] [ Porter Donale E. Hofmann Owen S. Rossbach Christopher J. Benn Alexander Witchel Emmett Operating systems transactionsinfrastructures 10.1145/1629575.1629591 978-1-60558-752-3 SOSP &apos;09: Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles ACM Big Sky, MT, USA 2009 ] Dragonfly BSD uses a technique similar to RCU that most closely resembles Linux&apos;s Sleepable RCU (SRCU) implementation. [ Advantages and disadvantages ] The ability to wait until all readers are done allows RCU readers to use much lighter-weight synchronization —in some cases, absolutely no synchronization at all. In contrast, in more conventional lock-based schemes, readers must use heavy-weight synchronization in order to prevent an updater from deleting the data structure out from under them. This is because lock-based updaters typically update data items in place, and must therefore exclude readers. In contrast, RCU-based updaters typically take advantage of the fact that writes to single aligned pointers are atomic on modern CPUs, allowing atomic insertion, removal, and replacement of data items in a linked structure without disrupting readers. Concurrent RCU readers can then continue accessing the old versions, and can dispense with the atomic operations, memory barriers, and cache misses that are so expensive on modern SMP computer systems, even in absence of lock contention. [ Hart Thomas E. McKenney Paul E. Demke Brown Angela Walpole Jonathan Performance of memory reclamation for lockless synchronization J. Parallel Distrib. Comput. 67 1270–1285 December 2007 ] [ McKenney Paul E. RCU part 2: Usage Linux Weekly News January 4, 2008 http://lwn.net/Articles/263130/ September 24, 2010 ] The lightweight nature of RCU&apos;s read-side primitives provides additional advantages beyond excellent performance, scalability, and real-time response. For example, they provide immunity to most deadlock and livelock conditions. { RCU-based deadlocks are still possible, for example by executing a statement that blocks until a grace period completes within an RCU read-side critical section. } Of course, RCU also has disadvantages. For example, RCU is a specialized technique that works best in situations with mostly reads and few updates, but is often less applicable to update-only workloads. For another example, although the fact that RCU readers and updaters may execute concurrently is what enables the lightweight nature of RCU&apos;s read-side primitives, some algorithms may not be amenable to read/update concurrency. Despite well over a decade of experience with RCU, the exact extent of its applicability is still a research topic. [ Patents ] The technique is covered by U.S. software patent 5,442,758, issued August 15, 1995 and assigned to Sequent Computer Systems, as well as by 5,608,893, 5,727,528, 6,219,690, and 6,886,162. The now-expired US Patent 4,809,168 covers a closely related technique. RCU is also the topic of one claim in the SCO v. IBM lawsuit. [ Sample RCU interface ] RCU is available in a number of operating systems, and was added to the Linux kernel in October 2002. User-level implementations such as liburcu are also available. [ Desnoyers Mathieu Low-Impact Operating System Tracing http://www.lttng.org/pub/thesis/desnoyers-dissertation-2009-12.pdf Ecole Polytechnique de Montreal December 2009 2009 ] The implementation of RCU in version 2.6 of the Linux kernel is among the better-known RCU implementations, and will be used as an inspiration for the RCU API in the remainder of this article. The core API ( Application Programming Interface ) is quite small: [ McKenney Paul E. RCU part 3: the RCU API Linux Weekly News January 17, 2008 http://lwn.net/Articles/264090/ September 24, 2010 ] rcu_read_lock(): Marks an RCU-protected data structure so that it won&apos;t be reclaimed for the full duration of that critical section. rcu_read_unlock(): Used by a reader to inform the reclaimer that the reader is exiting an RCU read-side critical section. Note that RCU read-side critical sections may be nested and/or overlapping. synchronize_rcu(): It blocks until all pre-existing RCU read-side critical sections on all CPUs have completed. Note that synchronize_rcu will not necessarily wait for any subsequent RCU read-side critical sections to complete. For example, consider the following sequence of events: CPU 0 CPU 1 CPU 2 ----------------- ------------------------- --------------- 1. rcu_read_lock() 2. enters synchronize_rcu() 3. rcu_read_lock() 4. rcu_read_unlock() 5. exits synchronize_rcu() 6. rcu_read_unlock() Since synchronize_rcu is the API that must figure out when readers are done, its implementation is key to RCU. For RCU to be useful in all but the most read-intensive situations, synchronize_rcu &apos;s overhead must also be quite small. Alternatively, instead of blocking, synchronize_rcu may register a callback to be invoked after all ongoing RCU read-side critical sections have completed. This callback variant is called call_rcu in the Linux kernel. rcu_assign_pointer(): The updater uses this function to assign a new value to an RCU-protected pointer, in order to safely communicate the change in value from the updater to the reader. This function returns the new value, and also executes any memory barrier instructions required for a given CPU architecture. Perhaps more importantly, it serves to document which pointers are protected by RCU. rcu_dereference_pointer(): The reader uses rcu_dereference_pointer to fetch an RCU-protected pointer, which returns a value that may then be safely dereferenced. It also executes any needed memory-barrier instructions for a given CPU architecture. The value returned by rcu_dereference_pointer is valid only within the enclosing RCU read-side critical section. As with rcu_assign_pointer, an important function of rcu_dereference_pointer is to document which pointers are protected by RCU. The following diagram shows how each API communicates among the reader, updater, and reclaimer. none The RCU infrastructure observes the time sequence of rcu_read_lock, rcu_read_unlock, synchronize_rcu, and call_rcu invocations in order to determine when (1) synchronize_rcu invocations may return to their callers and (2) call_rcu callbacks may be invoked. Efficient implementations of the RCU infrastructure make heavy use of batching in order to amortize their overhead over many uses of the corresponding APIs. [ What is a simple implementation of RCU? ] RCU has extremely simple &quot; toy &quot; implementations that can aid understanding of RCU. This section presents one such &quot; toy &quot; implementation that works in a non-preemptive environment. [ McKenney Paul E. Appavoo Jonathan Kleen Andi Krieger Orran Russell Rusty Sarma Dipankar Soni Maneesh Read-Copy Update http://www.rdrop.com/users/paulmck/RCU/rclock_OLS.2001.05.01c.pdf Ottawa Linux Symposium July 2001 2001 ] void rcu_read_lock(void) { } void rcu_read_unlock(void) { } void call_rcu(void (*callback) (void *), void *arg) { // add callback/arg pair to a list } void synchronize_rcu(void) { int cpu, ncpus = 0; for_each_cpu(cpu) { schedule_current_task_to(cpu); } { for each entry in the call_rcu list } { entry- &gt; callback (entry- &gt; arg); } } You can ignore rcu_assign_pointer and rcu_dereference_pointer without missing much. But here they are anyway. #define rcu_assign_pointer(p, v) ({ \ smp_wmb(); \ (p) = (v); \ }) #define rcu_dereference_pointer(p) ({ \ typeof(p) _value = (p); \ smp_rmb(); /* not needed on all architectures */ \ (_value); \ }) Note that rcu_read_lock and rcu_read_unlock do absolutely nothing. This is the great strength of classic RCU in a non-preemptive kernel: read-side overhead is precisely zero, as the memory barrier is actually needed only on DEC Alpha CPUs. [ Wizard The Shared Memory, Threads, Interprocess Communication Hewlett-Packard August 2001 http://www.openvms.compaq.com/wizard/wiz_2637.html December 26, 2010 ] And there is absolutely no way that rcu_read_lock can participate in a deadlock cycle, cause a realtime process to miss its scheduling deadline, precipitate priority inversion, or result in high lock contention. The implementation of synchronize_rcu moves the caller of synchronize_cpu to each CPU, thus blocking until all CPUs have been able to perform the context switch. Since there can be no preemption points within an RCU read-side critical section, if a given CPU executes a context switch (to schedule another process), we know that it must have completed all preceding RCU read-side critical sections. Once all CPUs have executed a context switch, then all preceding RCU read-side critical sections will have completed. [ Analogy with Reader-Writer Locking ] Although RCU can be used in many different ways, a very common use of RCU is analogous to reader-writer locking. The following side-by-side code display shows how closely related reader-writer locking (on the left) and RCU (on the right) can be. [ McKenney Paul E. Using {RCU} in the {Linux} 2.5 Kernel Linux Journal October 2003 http://www.linuxjournal.com/article/6993 September 24, 2010 ] { 1 struct el { 1 struct el { } { 2 struct list_head lp; 2 struct list_head lp; } { 3 long key; 3 long key; } { 4 spinlock_t mutex; 4 spinlock_t mutex; } { 5 int data; 5 int data; } { 6 /* Other data fields */ 6 /* Other data fields */ } { 7 }; 7 }; } { 8 DEFINE_RWLOCK(listmutex); 8 DEFINE_SPINLOCK(listmutex); } { 9 LIST_HEAD(head); 9 LIST_HEAD(head); } { 1 int search(long key, int *result) 1 int search(long key, int *result) } { 2 { 2 { } { 3 struct el *p; 3 struct el *p; } { 4 4 } { 5 read_lock( &amp; listmutex); 5 rcu_read_lock(); } { 6 list_for_each_entry(p, &amp; head, lp) { 6 list_for_each_entry_rcu(p, &amp; head, lp) { } { 7 if (p- &gt; key == key) { 7 if (p- &gt; key == key) { } { 8 *result = p- &gt; data; 8 *result = p- &gt; data; } { 9 read_unlock( &amp; listmutex); 9 rcu_read_unlock(); } 10 return 1; 10 return 1;11 } 11 }12 } 12 }13 read_unlock( &amp; listmutex); 13 rcu_read_unlock();14 return 0; 14 return 0;15 } 15 } { 1 int delete(long key) 1 int delete(long key) } { 2 { 2 { } { 3 struct el *p; 3 struct el *p; } { 4 4 } { 5 write_lock( &amp; listmutex); 5 spin_lock( &amp; listmutex); } { 6 list_for_each_entry(p, &amp; head, lp) { 6 list_for_each_entry(p, &amp; head, lp) { } { 7 if (p- &gt; key == key) { 7 if (p- &gt; key == key) { } { 8 list_del( &amp; p- &gt; lp); 8 list_del_rcu( &amp; p- &gt; lp); } { 9 write_unlock( &amp; listmutex); 9 spin_unlock( &amp; listmutex); } { 10 synchronize_rcu(); } 10 kfree(p); 11 kfree(p);11 return 1; 12 return 1;12 } 13 }13 } 14 }14 write_unlock( &amp; listmutex); 15 spin_unlock( &amp; listmutex);15 return 0; 16 return 0;16 } 17 } The differences between the two approaches are quite small. Read-side locking moves to rcu_read_lock and rcu_read_unlock, update-side locking moves from a reader-writer lock to a simple spinlock, and a synchronize_rcu precedes the kfree. However, there is one potential catch: the read-side and update-side critical sections can now run concurrently. In many cases, this will not be a problem, but it is necessary to check carefully regardless. For example, if multiple independent list updates must be seen as a single atomic update, converting to RCU will require special care. Also, the presence of synchronize_rcu means that the RCU version of delete can now block. If this is a problem, call_rcu could be used like call_rcu (kfree, p) in place of synchronize_rcu. This is especially useful in combination with reference counting. [ Explanation of name ] The name comes from the way that RCU is used to update a linked structure in place.A thread wishing to do this uses the following steps: create a new structure, copy the data from the old structure into the new one, and save a pointer to the old structure, modify the new, copied, structure update the global pointer to refer to the new structure, and then sleep until the operating system kernel determines that there are no readers left using the old structure, for example, in the Linux kernel, by using synchronize_rcu(). When the thread which made the copy is awakened by the kernel, it can safely deallocate the old structure. So the structure is read concurrently with a thread copying in order to do an update, hence the name &quot; read-copy update &quot;. The abbreviation &quot; RCU &quot; was one of many contributions by the Linux community. Other names for similar techniques include passive serialization and MP defer by VM/XA programmers and generations by K42 and Tornado programmers. [ History ] Techniques and mechanisms resembling RCU have been independently invented multiple times: [ McKenney Paul E. Exploiting Deferred Destruction: An Analysis of Read-Copy-Update Techniques http://www.rdrop.com/users/paulmck/RCU/RCUdissertation.2004.07.14e1.pdf OGI School of Science and Engineering at Oregon Health and Sciences University July 2004 2004 ] [ Kung H. T. Lehman Q. Concurrent Maintenance of Binary Search Trees http://portal.acm.org/citation.cfm?id%3D320619%26amp%3Bdl%3DGUIDE%2C ACM Transactions on Database Systems 5 September 1980 3 10.1145/320613.320619 354 ] [ Manber Udi Ladner Richard E. Concurrency Control in a Dynamic Search Structure ACM Transactions on Database Systems 9 September 1984 3 ] [ Rashid Richard Tevanian Avadis Young Michael Golub David Baron Robert Bolosky William Chew Jonathan Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures http://citeseer.csail.mit.edu/cache/papers/cs/6535/http%3AzSzzSzwww.cs.cornell.eduzSzcs614-sp98zSzberkeley-262zSzmach-vm.pdf/rashid87machineindependent.pdf Second Symposium on Architectural Support for Programming Languages and Operating Systems Association for Computing Machinery October, 1987 1987 ] [ Hennessy James P. Osisek Damian L. Seigh II Joseph W. Passive Serialization in a Multitasking Environment http://patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO1%26amp%3BSect2%3DHITOFF%26amp%3Bd%3DPALL%26amp%3Bp%3D1%26amp%3Bu%3D%2Fnetahtml%2FPTO%2Fsrchnum.htm%26amp%3Br%3D1%26amp%3Bf%3DG%26amp%3Bl%3D50%26amp%3Bs1%3D4809168.PN.%26amp%3BOS%3DPN%2F4809168%26amp%3BRS%3DPN%2F4809168 4,809,168 February, 1989 1989 ] [ Pugh William Concurrent Maintenance of Skip Lists http://portal.acm.org/citation.cfm?id%3DSERIES9310.93717 Institute of Advanced Computer Science Studies, Department of Computer Science, University of Maryland CS-TR-2222.1 June 1990 1990 ] [ John Aju Dynamic vnodes — design and implementation USENIX Winter 1995 https://www.usenix.org/publications/library/proceedings/neworl/full_papers/john.a January, 1995 1995 ] [ Slingwine John D. McKenney Paul E. Apparatus and Method for Achieving Reduced Overhead Mutual Exclusion and Maintaining Coherency in a Multiprocessor System http://patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO1%26amp%3BSect2%3DHITOFF%26amp%3Bd%3DPALL%26amp%3Bp%3D1%26amp%3Bu%3D%2Fnetahtml%2FPTO%2Fsrchnum.htm%26amp%3Br%3D1%26amp%3Bf%3DG%26amp%3Bl%3D50%26amp%3Bs1%3D5%2C442%2C758.PN.%26amp%3BOS%3DPN%2F5%2C442%2C758%26amp%3BRS%3DPN%2F5%2C442%2C758 5,442,758 August, 1995 1995 ] [ Gamsa Ben Krieger Orran Appavoo Jonathan Stumm Michael Tornado: Maximizing Locality and Concurrency in a Shared Memory Multiprocessor Operating System Proceedings of the Third Symposium on Operating System Design and Implementation http://www.usenix.org/events/osdi99/full_papers/gamsa/gamsa.pdf February 1999 1999 ] [ Russell Rusty Re: modular net drivers http://oss.sgi.com/projects/netdev/archive/2000-06/msg00250.html June, 2000 ] [ Russell Rusty Re: modular net drivers http://oss.sgi.com/projects/netdev/archive/2000-06/msg00254.html June, 2000 ] [ Colvin Robert Groves Lindsay Luchangco Victor Moir Mark Formal Verification of a Lazy Concurrent List-Based Set Algorithm Computer Aided Verification (CAV 2006) http://research.sun.com/scalable/pubs/CAV2006.pdf August, 2006 2006 ] H. T. Kung and Q. Lehman described use of garbage collectors to implement RCU-like access to a binary search tree. Udi Manber and Richard Ladner extended Kung&apos;s and Lehman&apos;s work to non-garbage-collected environments by deferring reclamation until all threads running at removal time have terminated, which works in environments that do not have long-lived threads. Richard Rashid et al. described a lazy translation lookaside buffer (TLB) implementation that deferred reclaiming virtual-address space until all CPUs flushed their TLB, which is similar in spirit to some RCU implementations. J. Hennessy, D. Osisek, and J. Seigh were granted US Patent 4,809,168 in 1989 (since lapsed). This patent describes an RCU-like mechanism that was apparently used in VM/XA on IBM Mainframe s. William Pugh described an RCU-like mechanism that relied on explicit flag-setting by readers. Aju John proposed an RCU-like implementation where updaters simply wait for a fixed period of time, under the assumption that readers would all complete within that fixed time, as might be appropriate in a hard real-time system. Van Jacobson proposed a similar scheme in 1993 (verbal communication). J. Slingwine and P. E. McKenney received US Patent 5,442,758 in August 1995, which describes RCU as implemented in DYNIX/ptx and later in the Linux kernel. B. Gamsa, O. Krieger, J. Appavoo, and M. Stumm described an RCU-like mechanism used in the University of Toronto Tornado research operating system and the closely related IBM Research K42 research operating systems. Rusty Russell and Phil Rumpf described RCU-like techniques for handling unloading of Linux kernel modules. D. Sarma added RCU to version 2.5.43 of the Linux kernel in October 2002. Robert Colvin et al. formally verified a lazy concurrent list-based set algorithm that resembles RCU. [ See also ] Concurrency control Multiversion concurrency control Contention Deadlock Lock (software engineering) Lock-free and wait-free algorithms Memory barrier Mutual exclusion Non-blocking synchronization Pre-emptive multitasking Priority inversion Real-time computing Starvation Synchronization [ Notes ] [ note ] [ References ] [ 30em ] [ External links ] [ 5442758 ] Paul E. McKenney and Jonathan Walpole: What is RCU, Fundamentally?, What is RCU? Part 2: Usage, and RCU part 3: the RCU API. Linux Weekly News. Paul E. McKenney&apos;s RCU web page Hart, McKenney, and Demke Brown (2006). Making Lockless Synchronization Fast: Performance Implications of Memory Reclamation An IPDPS 2006 Best Paper comparing RCU&apos;s performance to that of other lockless synchronization mechanisms. Journal version (including Walpole as author). (1995) &quot; Apparatus and method for achieving reduced overhead mutual exclusion and maintaining coherency in a multiprocessor system utilizing execution history and thread monitoring &quot; Paul McKenney: Sleepable RCU. Linux Weekly News. Category:Operating system technology Category:Concurrency control ja:リード・コピー・アップデート